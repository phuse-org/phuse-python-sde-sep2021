{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('phuse-python-sde-sep2021-nm3hVWFa': pipenv)"
  },
  "interpreter": {
   "hash": "80005f1e69ed79cadee62d99146642845dc91d593a729d8cfdee00bf657c6910"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Data\n",
    "\n",
    "In this workbook we will go over how you can load the data for our exercises\n",
    "\n",
    "We will be using the data from the PHUSE Open Data Repository\n",
    "\n",
    "Follow the instructions in [README.md](../README.md) to get setup\n",
    "\n",
    "##  Data processing in Python \n",
    "\n",
    "There are a couple of key libraries we will use:\n",
    "* [pandas](https://pandas.pydata.org/) - for processing data\n",
    "* [matplotlib](https://matplotlib.org/) - for creating visual representations of the data\n",
    "* [lxml](https://lxml.de) - processing the define.xml (or any other XML)\n",
    "\n",
    "You will find that in the majority of cases someone will have written a module to do what you want to do; all you need to do is be able to find it, and if necessary validate it.  Python Packages are published into the Python Package Index [PyPI](https://pypi.org) so you can search for a module using keywords, for example:\n",
    "* [Bayesian Analysis](https://pypi.org/search/?q=bayesian)\n",
    "* [Linear Regression](https://pypi.org/search/?q=linear+regression)\n",
    "* [ODM](https://pypi.org/search/?q=cdisc+odm)\n",
    "\n",
    "You can also create your own package repository or build packages from a git repository; this is a good way for a company to facilitate the building out of standard libraries for internal use or building out a validated Python module repository."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import the libraries we are going to use\n",
    "\n",
    "# Pandas data handling library\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "# Typing allows you to be typesafe with Python\n",
    "from typing import Optional\n",
    "# URLlib is the built in Library for working with the web\n",
    "import urllib\n",
    "# requests is a mode\n",
    "import requests\n",
    "# lxml is a library for processing XML documents\n",
    "from lxml import etree\n",
    "from lxml.etree import _ElementTree\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# define a prefix for where the files can be found\n",
    "PREFIX = \"https://github.com/phuse-org/phuse-scripts/raw/master/data/sdtm/cdiscpilot01/\"\n",
    "\n",
    "def check_link(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    ensure that the URL exists\n",
    "    :param url: The target URL we will attempt to load\n",
    "    \"\"\"\n",
    "    # this will attempt to open the URL, and extract the response status code\n",
    "    # - status codes are a HTTP convention for responding to requests\n",
    "    # 200 - OK\n",
    "    # 403 - Not authorized   \n",
    "    # 404 - Not found   \n",
    "    status_code = urllib.request.urlopen(url).getcode()\n",
    "    return status_code == 200\n",
    "\n",
    "def load_cdiscpilot_dataset(domain_prefix: str) -> Optional[DataFrame]:\n",
    "    \"\"\"\n",
    "    load a CDISC Pilot Dataset from the GitHub site\n",
    "    :param domain_prefix: The two letter Domain prefix that is used to id the dataset\n",
    "    \"\"\"\n",
    "    # define the target for our read_sas directive\n",
    "    target = f\"{PREFIX}{domain_prefix.lower()}.xpt\"\n",
    "    # make sure that the URL exists first\n",
    "    if check_link(target):\n",
    "        # load in the dataset \n",
    "        dataset = pd.read_sas(target, encoding=\"utf-8\")\n",
    "        # dataset = pd.read_sas(target)\n",
    "        return dataset\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_cdiscpilot_define() -> _ElementTree:\n",
    "    \"\"\"\n",
    "    load the define.xml for the CDISC Pilot project\n",
    "    \"\"\"\n",
    "    # define the target for our read_sas directive\n",
    "    target = f\"{PREFIX}define.xml\"\n",
    "    # make sure that the URL exists first\n",
    "    if check_link(target):\n",
    "        # load in the file \n",
    "        page = requests.get(target)\n",
    "        tree = etree.fromstring(page.content)\n",
    "        # dataset = pd.read_sas(target)\n",
    "        return tree\n",
    "    return None\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load in a dataset - DM\n",
    "dm = load_cdiscpilot_dataset('DM')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Take a look at a table\n",
    "dm.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate a Frequency Table for SEX\n",
    "pd.crosstab(index=dm[\"SEX\"], columns='count', colnames=[\"SEX\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# a two-way frequency table (Age by Sex)\n",
    "pd.crosstab(index=dm[\"AGE\"], columns=dm[\"SEX\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Distribution of ages for gender\n",
    "pd.crosstab(index=dm[\"AGE\"], columns=dm[\"SEX\"]).plot.bar()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate age distributions\n",
    "bins = [50, 55, 60, 65, 70, 75, 80, 85, 90]\n",
    "labels = [\"50-55\", \"55-60\", \"60-65\", \"65-70\", \"70-75\", \"75-80\", \"80-85\", \"85-90\"]\n",
    "dm[\"AGEBAND\"] = pd.cut(dm['AGE'], bins=bins, labels=labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the data using bands\n",
    "pd.crosstab(index=dm[\"AGEBAND\"], columns=dm[\"SEX\"]).plot.bar()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the VS dataset\n",
    "vs = load_cdiscpilot_dataset('VS')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Details on the VS dataset\n",
    "vs.shape\n",
    "\n",
    "print(f\"Dataset VS has {vs.shape[0]} records\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the first ten rows\n",
    "\n",
    "vs.loc[0:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate a distribution for the values\n",
    "\n",
    "tests = vs.groupby(\"VSTESTCD\")[\"VSORRES\"].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tests)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Weird right?  We need to check the type of the column\n",
    "vs.dtypes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ok, that makes sense - an object is not numeric....\n",
    "tests = vs.groupby(\"VSTESTCD\")[\"VSSTRESN\"].mean().reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tests)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Lets join the DM dataset\n",
    "\n",
    "labelled = vs.merge(dm, on=\"USUBJID\")\n",
    "labelled.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labelled_tests = labelled.groupby([\"VSTESTCD\",\"SEX\", \"AGEBAND\"])[\"VSSTRESN\"].mean().reset_index()\n",
    "print(labelled_tests)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# now, let's look at the define\n",
    "\n",
    "# the way we do this is to load the content from the URL, and then pass it off to the XML parsing library\n",
    "odm = load_cdiscpilot_define()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Â XML documents can be treated as a tree, \n",
    "# * root item (root)\n",
    "# * elements (branches)\n",
    "# * attributes (leaves)\n",
    "\n",
    "# In this case we have a root item that is an CDISC Operational Data Model (ODM)\n",
    "# `tag` is the way of working out what type of element we have\n",
    "print(odm.tag)\n",
    "\n",
    "# we can look at the attributes using the .get method\n",
    "print(odm.get(\"FileOID\"))\n",
    "print(odm.get(\"CreationDateTime\"))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Namespaces\n",
    "\n",
    "XML documents use a schema document to define what elements/attributes are permissible (or required/expected).  It is possible to extend a schema to incorporate extra elements/attributes; these attributes exist alongside the existing elements by having them under different namespaces\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# look at the namespaces\n",
    "print(odm.nsmap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# in this the default namespace is ODM 1.2, with define.xml present in the def namespace\n",
    "\n",
    "# let's get the MetadataVersion element\n",
    "nsmap = odm.nsmap\n",
    "nsmap[\"ODM\"] = odm.nsmap.get(None)\n",
    "mdv = odm.find(\".//ODM:MetaDataVersion\", nsmap)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# let's take a look at the define attributes\n",
    "define_ns = nsmap.get('def')\n",
    "print(define_ns)\n",
    "# get the define version\n",
    "for attribute in (\"DefineVersion\", \"StandardName\", \"StandardVersion\"):\n",
    "    #Â attributes should be prefixed with the namespace\n",
    "    attr = f\"{{{define_ns}}}{attribute}\"\n",
    "    if mdv.get(attr):\n",
    "        print(f\"{attribute} -> {mdv.get(attr)}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remember the Standard Version here!  We will come back to it\n",
    "\n",
    "# you can scan over the different child elements using the findall method\n",
    "for itemdef in mdv.findall(\"./ODM:ItemDef\", namespaces=nsmap):\n",
    "    if itemdef.find(\"./ODM:CodeListRef\", namespaces=nsmap) is not None:\n",
    "        codelistref = itemdef.find(\"./ODM:CodeListRef\", namespaces=nsmap)\n",
    "        print(f\"Item {itemdef.get('OID')} has CodeList: {codelistref.get('CodeListOID')}\")\n",
    "    else:\n",
    "        print(f\"Item: {itemdef.get('OID')}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading XML is a very useful technique, this example is a simple load and navigate of the define data structure.  I recommend checking out [odmlib](https://pypi.org/project/odmlib/) which is a library that makes processing and manipulation of CDISC ODM documents much more straight forward (written by the venerable [Sam Hume](https://github.com/swhume))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "In this set we've gone over some elementary activities dealing accessing/loading data; there were some elementary expeditions into how data can be manipulated/visualised using pandas and some simple navigation of an XML document.  \n",
    "\n",
    "Next we're going to take a look at how accessing data over the web works."
   ],
   "metadata": {}
  }
 ]
}